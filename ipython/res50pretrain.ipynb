{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangs/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D, Concatenate, MaxPooling2D,Activation\n",
    "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from tqdm import tqdm_notebook\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.engine import InputSpec\n",
    "from keras import backend as K\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.engine.topology import Input\n",
    "from keras.engine.training import Model\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.core import Activation, SpatialDropout2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 128\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n",
    "    #res[:img_size_ori, :img_size_ori] = img\n",
    "    #return res\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "    #return img[:img_size_ori, :img_size_ori]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangs/anaconda3/lib/python3.5/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangs/anaconda3/lib/python3.5/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.2, stratify=train_df.coverage_class, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block_simple(prevlayer, filters, prefix, strides=(1, 1)):\n",
    "    conv = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", strides=strides, name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = BatchNormalization(name=prefix + \"_bn\")(conv)\n",
    "    conv = SpatialDropout2D(0.5)(conv)\n",
    "    conv = Activation('relu', name=prefix + \"_activation\")(conv)\n",
    "    return conv\n",
    "\n",
    "def conv_block_simple_no_bn(prevlayer, filters, prefix, strides=(1, 1)):\n",
    "    conv = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", strides=strides, name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Activation('relu', name=prefix + \"_activation\")(conv)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "def get_unet_resnet(input_shape):\n",
    "    resnet_base = ResNet50(input_shape=input_shape, include_top=False)\n",
    "\n",
    "    for l in resnet_base.layers:\n",
    "        l.trainable = True\n",
    "    conv1 = resnet_base.get_layer(\"activation_1\").output\n",
    "    conv2 = resnet_base.get_layer(\"activation_10\").output\n",
    "    conv3 = resnet_base.get_layer(\"activation_22\").output\n",
    "    conv4 = resnet_base.get_layer(\"activation_40\").output\n",
    "    conv5 = resnet_base.get_layer(\"activation_49\").output\n",
    "\n",
    "    up6 = concatenate([UpSampling2D()(conv5), conv4], axis=-1)\n",
    "    conv6 = conv_block_simple(up6, 512, \"conv6_1\")\n",
    "    conv6 = conv_block_simple(conv6, 512, \"conv6_2\")#512\n",
    "\n",
    "    up7 = concatenate([UpSampling2D()(conv6), conv3], axis=-1)\n",
    "    conv7 = conv_block_simple(up7, 256, \"conv7_1\")\n",
    "    conv7 = conv_block_simple(conv7, 256, \"conv7_2\")#256\n",
    "\n",
    "    up8 = concatenate([UpSampling2D()(conv7), conv2], axis=-1)\n",
    "    conv8 = conv_block_simple(up8, 128, \"conv8_1\")\n",
    "    conv8 = conv_block_simple(conv8, 128, \"conv8_2\")#128\n",
    "\n",
    "    up9 = concatenate([UpSampling2D()(conv8), conv1], axis=-1)\n",
    "    conv9 = conv_block_simple(up9, 64, \"conv9_1\")\n",
    "    conv9 = conv_block_simple(conv9, 64, \"conv9_2\") #64\n",
    "\n",
    "    up10 = UpSampling2D()(conv9)\n",
    "    conv10 = conv_block_simple(up10, 32, \"conv10_1\")\n",
    "    conv10 = conv_block_simple(conv10, 32, \"conv10_2\")\n",
    "    conv10 = SpatialDropout2D(0.2)(conv10)\n",
    "    x = Conv2D(1, (1, 1), name=\"prediction\")(conv10) #sigmoid activation=\"linear\"\n",
    "    x = Activation('sigmoid')(x)\n",
    "    model = Model(resnet_base.input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'keras.., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'keras.., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ResNet50(include_top=True, weights='imagenet',\n",
    "             input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1000):\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "#     x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "\n",
    "#     if include_top:\n",
    "#         x = Flatten()(x)\n",
    "#         x = Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "#     else:\n",
    "#         if pooling == 'avg':\n",
    "#             x = GlobalAveragePooling2D()(x)\n",
    "#         elif pooling == 'max':\n",
    "#             x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnet50')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
    "        else:\n",
    "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n",
    "        model.load_weights(weights_path,by_name=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_unet_resnet(input_shape=(img_size_target,img_size_target,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 64, 64)   9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 64, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 32, 32, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 32, 32, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 32, 32, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 32, 32, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 32, 32, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 32, 32, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 32, 32, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 32, 32, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 32, 32, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 32, 32, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 32, 32, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 16, 16, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 16, 16, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 16, 16, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 16, 16, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 16, 16, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 16, 16, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 16, 16, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 16, 16, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 16, 16, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 16, 16, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 16, 16, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 8, 8, 256)    131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 8, 8, 1024)   525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 8, 8, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 8, 8, 256)    262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 8, 8, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 8, 8, 256)    590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 8, 8, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 8, 8, 1024)   263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 8, 8, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 1024)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 4, 4, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 4, 4, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 4, 4, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 4, 4, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 4, 4, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 8, 8, 2048)   0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 3072)   0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_conv (Conv2D)           (None, 8, 8, 1024)   28312576    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_bn (BatchNormalization) (None, 8, 8, 1024)   4096        conv6_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8, 1024)   0           conv6_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_activation (Activation) (None, 8, 8, 1024)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_conv (Conv2D)           (None, 8, 8, 1024)   9438208     conv6_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_bn (BatchNormalization) (None, 8, 8, 1024)   4096        conv6_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 1024)   0           conv6_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_activation (Activation) (None, 8, 8, 1024)   0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 16, 16, 1024) 0           conv6_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 1536) 0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_conv (Conv2D)           (None, 16, 16, 512)  7078400     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_bn (BatchNormalization) (None, 16, 16, 512)  2048        conv7_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 512)  0           conv7_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_activation (Activation) (None, 16, 16, 512)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_conv (Conv2D)           (None, 16, 16, 256)  1179904     conv7_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_bn (BatchNormalization) (None, 16, 16, 256)  1024        conv7_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 256)  0           conv7_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_activation (Activation) (None, 16, 16, 256)  0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 256)  0           conv7_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 512)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_conv (Conv2D)           (None, 32, 32, 128)  589952      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_bn (BatchNormalization) (None, 32, 32, 128)  512         conv8_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 128)  0           conv8_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_activation (Activation) (None, 32, 32, 128)  0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_conv (Conv2D)           (None, 32, 32, 128)  147584      conv8_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_bn (BatchNormalization) (None, 32, 32, 128)  512         conv8_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 128)  0           conv8_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_activation (Activation) (None, 32, 32, 128)  0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 128)  0           conv8_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 192)  0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_conv (Conv2D)           (None, 64, 64, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_bn (BatchNormalization) (None, 64, 64, 64)   256         conv9_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 64)   0           conv9_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_activation (Activation) (None, 64, 64, 64)   0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_conv (Conv2D)           (None, 64, 64, 64)   36928       conv9_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_bn (BatchNormalization) (None, 64, 64, 64)   256         conv9_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 64, 64)   0           conv9_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_activation (Activation) (None, 64, 64, 64)   0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 64) 0           conv9_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_conv (Conv2D)          (None, 128, 128, 32) 18464       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_bn (BatchNormalization (None, 128, 128, 32) 128         conv10_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128, 128, 32) 0           conv10_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_activation (Activation (None, 128, 128, 32) 0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_conv (Conv2D)          (None, 128, 128, 32) 9248        conv10_1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_bn (BatchNormalization (None, 128, 128, 32) 128         conv10_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128, 128, 32) 0           conv10_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_activation (Activation (None, 128, 128, 32) 0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 128, 128, 32) 0           conv10_2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 128, 128, 1)  33          spatial_dropout2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128, 128, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 70,522,721\n",
      "Trainable params: 70,463,073\n",
      "Non-trainable params: 59,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0        \n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = weight * (logit_y_pred * (1. - y_true) + \n",
    "                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Lovasz-Softmax and Jaccard hinge loss in Tensorflow\n",
    "Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        #losses.set_shape((None,))\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "# --------------------------- MULTICLASS LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_softmax(probas, labels, classes='all', per_image=False, ignore=None, order='BHWC'):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, H, W, C] or [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "      order: use BHWC or BCHW\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(prob_lab):\n",
    "            prob, lab = prob_lab\n",
    "            prob, lab = tf.expand_dims(prob, 0), tf.expand_dims(lab, 0)\n",
    "            prob, lab = flatten_probas(prob, lab, ignore, order)\n",
    "            return lovasz_softmax_flat(prob, lab, classes=classes)\n",
    "        losses = tf.map_fn(treat_image, (probas, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore, order), classes=classes)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, classes='all'):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "    \"\"\"\n",
    "    C = 1\n",
    "    losses = []\n",
    "    present = []\n",
    "    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n",
    "    for c in class_to_sum:\n",
    "        fg = tf.cast(tf.equal(labels, c), probas.dtype)  # foreground for class c\n",
    "        if classes == 'present':\n",
    "            present.append(tf.reduce_sum(fg) > 0)\n",
    "        errors = tf.abs(fg - probas[:, c])\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort_{}\".format(c))\n",
    "        fg_sorted = tf.gather(fg, perm)\n",
    "        grad = lovasz_grad(fg_sorted)\n",
    "        losses.append(\n",
    "            tf.tensordot(errors_sorted, tf.stop_gradient(grad), 1, name=\"loss_class_{}\".format(c))\n",
    "                      )\n",
    "    if len(class_to_sum) == 1:  # short-circuit mean when only one class\n",
    "        return losses[0]\n",
    "    losses_tensor = tf.stack(losses)\n",
    "    if classes == 'present':\n",
    "        present = tf.stack(present)\n",
    "        losses_tensor = tf.boolean_mask(losses_tensor, present)\n",
    "    loss = tf.reduce_mean(losses_tensor)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None, order='BHWC'):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    if order == 'BCHW':\n",
    "        probas = tf.transpose(probas, (0, 2, 3, 1), name=\"BCHW_to_BHWC\")\n",
    "        order = 'BHWC'\n",
    "    if order != 'BHWC':\n",
    "        raise NotImplementedError('Order {} unknown'.format(order))\n",
    "    C = 1\n",
    "    probas = tf.reshape(probas, (-1, C))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vprobas = tf.boolean_mask(probas, valid, name='valid_probas')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vprobas, vlabels\n",
    "\n",
    "def keras_lovasz_softmax(labels,probas):\n",
    "    #return lovasz_softmax(probas, labels)+binary_crossentropy(labels, probas)\n",
    "    return lovasz_softmax(probas, labels)\n",
    "\n",
    "def keras_lovasz_hinge(labels,logits):\n",
    "    return lovasz_hinge(logits, labels, per_image=True, ignore=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam,SGD\n",
    "#finetue\n",
    "#model.load_weights('res50_keras.model')\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "#sgd  = SGD(lr=0.0005, momentum=0.9, decay=0.0001, nesterov=False)\n",
    "model.compile(loss=bce_dice_loss, optimizer=adam, metrics=[my_iou_metric])\n",
    "#model.compile(loss=keras_lovasz_hinge, optimizer=sgd, metrics=[my_iou_metric])\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "x_train = np.repeat(x_train,3,axis=3)\n",
    "x_valid = np.repeat(x_valid,3,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/80\n",
      "6400/6400 [==============================] - 88s 14ms/step - loss: 0.9231 - my_iou_metric: 0.2448 - val_loss: 1.0267 - val_my_iou_metric: 0.4651\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.46512, saving model to res50_keras_dp06.model\n",
      "Epoch 2/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.5710 - my_iou_metric: 0.5600 - val_loss: 0.4656 - val_my_iou_metric: 0.6979\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.46512 to 0.69787, saving model to res50_keras_dp06.model\n",
      "Epoch 3/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.4561 - my_iou_metric: 0.6653 - val_loss: 0.4157 - val_my_iou_metric: 0.7255\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.69787 to 0.72550, saving model to res50_keras_dp06.model\n",
      "Epoch 4/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.3905 - my_iou_metric: 0.7030 - val_loss: 0.3732 - val_my_iou_metric: 0.7240\n",
      "\n",
      "Epoch 00004: val_my_iou_metric did not improve from 0.72550\n",
      "Epoch 5/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.3335 - my_iou_metric: 0.7386 - val_loss: 0.3588 - val_my_iou_metric: 0.7204\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.72550\n",
      "Epoch 6/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.2901 - my_iou_metric: 0.7622 - val_loss: 0.3294 - val_my_iou_metric: 0.7597\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.72550 to 0.75975, saving model to res50_keras_dp06.model\n",
      "Epoch 7/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.2622 - my_iou_metric: 0.7668 - val_loss: 0.3954 - val_my_iou_metric: 0.7066\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.75975\n",
      "Epoch 8/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.2473 - my_iou_metric: 0.7757 - val_loss: 0.3461 - val_my_iou_metric: 0.7315\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.75975\n",
      "Epoch 9/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.2214 - my_iou_metric: 0.7885 - val_loss: 0.3832 - val_my_iou_metric: 0.7441\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.75975\n",
      "Epoch 10/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.2212 - my_iou_metric: 0.7851 - val_loss: 0.3055 - val_my_iou_metric: 0.7603\n",
      "\n",
      "Epoch 00010: val_my_iou_metric improved from 0.75975 to 0.76025, saving model to res50_keras_dp06.model\n",
      "Epoch 11/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.1653 - my_iou_metric: 0.8248 - val_loss: 0.4533 - val_my_iou_metric: 0.7266\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.76025\n",
      "Epoch 12/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.1578 - my_iou_metric: 0.8275 - val_loss: 0.8818 - val_my_iou_metric: 0.6202\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.76025\n",
      "Epoch 13/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.1615 - my_iou_metric: 0.8116 - val_loss: 0.3823 - val_my_iou_metric: 0.7439\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.76025\n",
      "Epoch 14/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.1432 - my_iou_metric: 0.8301 - val_loss: 0.9018 - val_my_iou_metric: 0.6815\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve from 0.76025\n",
      "Epoch 15/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.1215 - my_iou_metric: 0.8430 - val_loss: 0.2960 - val_my_iou_metric: 0.7849\n",
      "\n",
      "Epoch 00015: val_my_iou_metric improved from 0.76025 to 0.78488, saving model to res50_keras_dp06.model\n",
      "Epoch 16/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.1324 - my_iou_metric: 0.8296 - val_loss: 0.3472 - val_my_iou_metric: 0.7682\n",
      "\n",
      "Epoch 00016: val_my_iou_metric did not improve from 0.78488\n",
      "Epoch 17/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.1421 - my_iou_metric: 0.8217 - val_loss: 0.3365 - val_my_iou_metric: 0.7584\n",
      "\n",
      "Epoch 00017: val_my_iou_metric did not improve from 0.78488\n",
      "Epoch 18/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.1037 - my_iou_metric: 0.8563 - val_loss: 0.3445 - val_my_iou_metric: 0.7795\n",
      "\n",
      "Epoch 00018: val_my_iou_metric did not improve from 0.78488\n",
      "Epoch 19/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0942 - my_iou_metric: 0.8605 - val_loss: 0.3299 - val_my_iou_metric: 0.7697\n",
      "\n",
      "Epoch 00019: val_my_iou_metric did not improve from 0.78488\n",
      "Epoch 20/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.1031 - my_iou_metric: 0.8532 - val_loss: 0.4242 - val_my_iou_metric: 0.7504\n",
      "\n",
      "Epoch 00020: val_my_iou_metric did not improve from 0.78488\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 21/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0927 - my_iou_metric: 0.8640 - val_loss: 0.3235 - val_my_iou_metric: 0.7914\n",
      "\n",
      "Epoch 00021: val_my_iou_metric improved from 0.78488 to 0.79138, saving model to res50_keras_dp06.model\n",
      "Epoch 22/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0873 - my_iou_metric: 0.8732 - val_loss: 0.3097 - val_my_iou_metric: 0.7964\n",
      "\n",
      "Epoch 00022: val_my_iou_metric improved from 0.79138 to 0.79637, saving model to res50_keras_dp06.model\n",
      "Epoch 23/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0820 - my_iou_metric: 0.8773 - val_loss: 0.3121 - val_my_iou_metric: 0.8000\n",
      "\n",
      "Epoch 00023: val_my_iou_metric improved from 0.79637 to 0.80000, saving model to res50_keras_dp06.model\n",
      "Epoch 24/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0790 - my_iou_metric: 0.8788 - val_loss: 0.3152 - val_my_iou_metric: 0.7994\n",
      "\n",
      "Epoch 00024: val_my_iou_metric did not improve from 0.80000\n",
      "Epoch 25/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0763 - my_iou_metric: 0.8818 - val_loss: 0.3185 - val_my_iou_metric: 0.8037\n",
      "\n",
      "Epoch 00025: val_my_iou_metric improved from 0.80000 to 0.80375, saving model to res50_keras_dp06.model\n",
      "Epoch 26/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0745 - my_iou_metric: 0.8843 - val_loss: 0.3196 - val_my_iou_metric: 0.8044\n",
      "\n",
      "Epoch 00026: val_my_iou_metric improved from 0.80375 to 0.80437, saving model to res50_keras_dp06.model\n",
      "Epoch 27/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0748 - my_iou_metric: 0.8852 - val_loss: 0.3207 - val_my_iou_metric: 0.7981\n",
      "\n",
      "Epoch 00027: val_my_iou_metric did not improve from 0.80437\n",
      "Epoch 28/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0731 - my_iou_metric: 0.8879 - val_loss: 0.3199 - val_my_iou_metric: 0.8044\n",
      "\n",
      "Epoch 00028: val_my_iou_metric did not improve from 0.80437\n",
      "Epoch 29/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0716 - my_iou_metric: 0.8870 - val_loss: 0.3261 - val_my_iou_metric: 0.8041\n",
      "\n",
      "Epoch 00029: val_my_iou_metric did not improve from 0.80437\n",
      "Epoch 30/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0699 - my_iou_metric: 0.8890 - val_loss: 0.3286 - val_my_iou_metric: 0.8060\n",
      "\n",
      "Epoch 00030: val_my_iou_metric improved from 0.80437 to 0.80600, saving model to res50_keras_dp06.model\n",
      "Epoch 31/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0705 - my_iou_metric: 0.8894 - val_loss: 0.3306 - val_my_iou_metric: 0.8066\n",
      "\n",
      "Epoch 00031: val_my_iou_metric improved from 0.80600 to 0.80662, saving model to res50_keras_dp06.model\n",
      "Epoch 32/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0686 - my_iou_metric: 0.8948 - val_loss: 0.3337 - val_my_iou_metric: 0.8015\n",
      "\n",
      "Epoch 00032: val_my_iou_metric did not improve from 0.80662\n",
      "Epoch 33/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0669 - my_iou_metric: 0.8961 - val_loss: 0.3366 - val_my_iou_metric: 0.8044\n",
      "\n",
      "Epoch 00033: val_my_iou_metric did not improve from 0.80662\n",
      "Epoch 34/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0664 - my_iou_metric: 0.8962 - val_loss: 0.3399 - val_my_iou_metric: 0.8028\n",
      "\n",
      "Epoch 00034: val_my_iou_metric did not improve from 0.80662\n",
      "Epoch 35/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0669 - my_iou_metric: 0.8964 - val_loss: 0.3373 - val_my_iou_metric: 0.8064\n",
      "\n",
      "Epoch 00035: val_my_iou_metric did not improve from 0.80662\n",
      "Epoch 36/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0650 - my_iou_metric: 0.8985 - val_loss: 0.3381 - val_my_iou_metric: 0.8054\n",
      "\n",
      "Epoch 00036: val_my_iou_metric did not improve from 0.80662\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 37/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0635 - my_iou_metric: 0.9014 - val_loss: 0.3390 - val_my_iou_metric: 0.8045\n",
      "\n",
      "Epoch 00037: val_my_iou_metric did not improve from 0.80662\n",
      "Epoch 38/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0655 - my_iou_metric: 0.8980 - val_loss: 0.3401 - val_my_iou_metric: 0.8058\n",
      "\n",
      "Epoch 00038: val_my_iou_metric did not improve from 0.80662\n",
      "Epoch 39/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0635 - my_iou_metric: 0.9002 - val_loss: 0.3392 - val_my_iou_metric: 0.8043\n",
      "\n",
      "Epoch 00039: val_my_iou_metric did not improve from 0.80662\n",
      "Epoch 40/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0623 - my_iou_metric: 0.9011 - val_loss: 0.3398 - val_my_iou_metric: 0.8066\n",
      "\n",
      "Epoch 00040: val_my_iou_metric improved from 0.80662 to 0.80663, saving model to res50_keras_dp06.model\n",
      "Epoch 41/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0665 - my_iou_metric: 0.8974 - val_loss: 0.3394 - val_my_iou_metric: 0.8070\n",
      "\n",
      "Epoch 00041: val_my_iou_metric improved from 0.80663 to 0.80700, saving model to res50_keras_dp06.model\n",
      "Epoch 42/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0626 - my_iou_metric: 0.9009 - val_loss: 0.3407 - val_my_iou_metric: 0.8063\n",
      "\n",
      "Epoch 00042: val_my_iou_metric did not improve from 0.80700\n",
      "Epoch 43/80\n",
      "6400/6400 [==============================] - 79s 12ms/step - loss: 0.0630 - my_iou_metric: 0.9009 - val_loss: 0.3403 - val_my_iou_metric: 0.8050\n",
      "\n",
      "Epoch 00043: val_my_iou_metric did not improve from 0.80700\n",
      "Epoch 44/80\n",
      " 320/6400 [>.............................] - ETA: 1:12 - loss: 0.0765 - my_iou_metric: 0.8572"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d12bfca59c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     callbacks=[model_checkpoint, reduce_lr],shuffle=True,verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2670\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2654\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(\"res50_keras_dp06.model\",monitor='val_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric',mode = 'max',factor=0.1, patience=5, \n",
    "                              min_lr=0.000001, verbose=1)\n",
    "\n",
    "epochs = 80\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint, reduce_lr],shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del ids_train, x_train, y_train, cov_train,depth_train,depths_df,depth_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8e4b95333665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'my_iou_metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_my_iou_metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_my_iou_metric'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "plt.plot(history.history['my_iou_metric'][1:])\n",
    "plt.plot(history.history['val_my_iou_metric'][1:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('val_my_iou_metric')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('res50_keras_dp06.model.model')\n",
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test1 = model.predict([x_test]).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2_refect = model.predict([x_test_reflect]).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2 = np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    preds_avg = (preds_test1 +preds_test2)/2\n",
    "    return preds_avg\n",
    "preds_valid = predict_result(model,x_valid,img_size_target)\n",
    "preds_valid = np.array([downsample(x) for x in preds_valid])\n",
    "y_valid_ori = np.array([downsample(x) for x in y_valid])\n",
    "\n",
    "\n",
    "\n",
    "max_images = 60\n",
    "grid_width = 15\n",
    "grid_height = int(max_images / grid_width)\n",
    "fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n",
    "for i, idx in enumerate(ids_valid[:max_images]):\n",
    "    img = train_df.loc[idx].images\n",
    "    mask = train_df.loc[idx].masks\n",
    "    pred = preds_valid[i]\n",
    "    ax = axs[int(i / grid_width), i % grid_width]\n",
    "    ax.imshow(img, cmap=\"Greys\")\n",
    "    ax.imshow(mask, alpha=0.3, cmap=\"Greens\")\n",
    "    ax.imshow(pred, alpha=0.3, cmap=\"OrRd\")\n",
    "    ax.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n",
    "    ax.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n",
    "    ax.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "plt.suptitle(\"Green: salt, Red: prediction. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Scoring for last model\n",
    "thresholds = np.linspace(0.3, 0.7, 31)\n",
    "ious = np.array([iou_metric_batch(y_valid_ori, np.int32(preds_valid > threshold)) for threshold in tqdm_notebook(thresholds)])\n",
    "\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x_valid, y_valid,preds_valid,y_valid_ori,train_df\n",
    "gc.collect()\n",
    "def rle_encode(im):\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "batch_size = 500\n",
    "preds_test = []\n",
    "i = 0\n",
    "while i < test_df.shape[0]:\n",
    "    print('Images Processed:',i)\n",
    "    index_val = test_df.index[i:i+batch_size]\n",
    "    depth_val = test_df.z[i:i+batch_size]\n",
    "    x_test = np.array([upsample(np.array(load_img(\"test/images/{}.png\".format(idx), grayscale=True))) / 255 for idx in (index_val)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    x_test = np.repeat(x_test,3,axis=3)\n",
    "    preds_test_temp = predict_result(model,x_test,img_size_target)\n",
    "    if i==0:\n",
    "        preds_test = preds_test_temp\n",
    "    else:\n",
    "        preds_test = np.concatenate([preds_test,preds_test_temp],axis=0)\n",
    "#     print(preds_test.shape)\n",
    "    i += batch_size\n",
    "    \n",
    "\n",
    "del x_test,preds_test_temp\n",
    "gc.collect()\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "#print(f\"Usedtime = {t2-t1} s\")\n",
    "\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('res50_keras_lovasz.model_pretrained_submission.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
