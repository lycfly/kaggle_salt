{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "d2c036df295691c7305bfd3d5cac5f225db157d4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangs/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63faa3b80c7f40e8a706cb8b195c1793"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangs/anaconda3/lib/python3.5/site-packages/keras_preprocessing/image.py:489: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8402cb266a246269da3f008583354b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** Max depth in train set is :959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cced487762490eb7e114c78abac726"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ddabaa7c4444179f4d27fe225074d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>images</th>\n",
       "      <th>masks</th>\n",
       "      <th>coverage</th>\n",
       "      <th>coverage_class</th>\n",
       "      <th>depth</th>\n",
       "      <th>images_d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575d24d81d</th>\n",
       "      <td>843</td>\n",
       "      <td>[[0.5254901960784314, 0.5137254901960784, 0.52...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.8790406673618353, 0.8790406673618353, 0.87...</td>\n",
       "      <td>[[[0.5254901960784314, 0.8790406673618353], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a266a2a9df</th>\n",
       "      <td>794</td>\n",
       "      <td>[[0.3411764705882353, 0.3764705882352941, 0.33...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>6</td>\n",
       "      <td>[[0.8279457768508863, 0.8279457768508863, 0.82...</td>\n",
       "      <td>[[[0.3411764705882353, 0.8279457768508863], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75efad62c1</th>\n",
       "      <td>468</td>\n",
       "      <td>[[0.5686274509803921, 0.4666666666666667, 0.32...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.993334</td>\n",
       "      <td>10</td>\n",
       "      <td>[[0.4880083420229406, 0.4880083420229406, 0.48...</td>\n",
       "      <td>[[[0.5686274509803921, 0.4880083420229406], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34e51dba6a</th>\n",
       "      <td>727</td>\n",
       "      <td>[[0.5411764705882353, 0.4745098039215686, 0.39...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.149201</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.7580813347236705, 0.7580813347236705, 0.75...</td>\n",
       "      <td>[[[0.5411764705882353, 0.7580813347236705], [0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875705fb0</th>\n",
       "      <td>797</td>\n",
       "      <td>[[0.06666666666666667, 0.0784313725490196, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.042839</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.8310740354535975, 0.8310740354535975, 0.83...</td>\n",
       "      <td>[[[0.06666666666666667, 0.8310740354535975], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              z                                             images  \\\n",
       "id                                                                   \n",
       "575d24d81d  843  [[0.5254901960784314, 0.5137254901960784, 0.52...   \n",
       "a266a2a9df  794  [[0.3411764705882353, 0.3764705882352941, 0.33...   \n",
       "75efad62c1  468  [[0.5686274509803921, 0.4666666666666667, 0.32...   \n",
       "34e51dba6a  727  [[0.5411764705882353, 0.4745098039215686, 0.39...   \n",
       "4875705fb0  797  [[0.06666666666666667, 0.0784313725490196, 0.0...   \n",
       "\n",
       "                                                        masks  coverage  \\\n",
       "id                                                                        \n",
       "575d24d81d  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  0.000000   \n",
       "a266a2a9df  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  0.504950   \n",
       "75efad62c1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  0.993334   \n",
       "34e51dba6a  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  0.149201   \n",
       "4875705fb0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  0.042839   \n",
       "\n",
       "            coverage_class                                              depth  \\\n",
       "id                                                                              \n",
       "575d24d81d               0  [[0.8790406673618353, 0.8790406673618353, 0.87...   \n",
       "a266a2a9df               6  [[0.8279457768508863, 0.8279457768508863, 0.82...   \n",
       "75efad62c1              10  [[0.4880083420229406, 0.4880083420229406, 0.48...   \n",
       "34e51dba6a               2  [[0.7580813347236705, 0.7580813347236705, 0.75...   \n",
       "4875705fb0               1  [[0.8310740354535975, 0.8310740354535975, 0.83...   \n",
       "\n",
       "                                                     images_d  \n",
       "id                                                             \n",
       "575d24d81d  [[[0.5254901960784314, 0.8790406673618353], [0...  \n",
       "a266a2a9df  [[[0.3411764705882353, 0.8279457768508863], [0...  \n",
       "75efad62c1  [[[0.5686274509803921, 0.4880083420229406], [0...  \n",
       "34e51dba6a  [[[0.5411764705882353, 0.7580813347236705], [0...  \n",
       "4875705fb0  [[[0.06666666666666667, 0.8310740354535975], [...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout ,BatchNormalization\n",
    "from keras import backend as K\n",
    "from tqdm import tqdm_notebook,tnrange\n",
    "from skimage.util import pad\n",
    "\n",
    "# 准备\n",
    "img_size_ori = 101\n",
    "img_size_target = 256\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n",
    "    #res[:img_size_ori, :img_size_ori] = img\n",
    "    #return res\n",
    "def upsample_v2(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (256, 256), mode='constant', preserve_range=True)\n",
    "    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n",
    "    #res[:img_size_ori, :img_size_ori] = img\n",
    "    #return res    \n",
    "def reflect_pad(img):\n",
    "    return pad(resize(img, (101*2, 101*2), mode='constant', preserve_range=True),27,'reflect')\n",
    "\n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "    #return img[:img_size_ori, :img_size_ori]\n",
    "\n",
    "train_df = pd.read_csv(\"/home/zhangs/lyc/salt/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"/home/zhangs/lyc/salt/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]#将生成id不在train中的样本id集合\n",
    "train_df[\"images\"] = [np.array(load_img(\"/home/zhangs/lyc/salt/train/images/{}.png\".format(idx), grayscale=True))/ 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"/home/zhangs/lyc/salt/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n",
    "# 将深度信息放入训练图像\n",
    "MAX_DEPTH = max(train_df[\"z\"])\n",
    "print('**** Max depth in train set is :'+str(MAX_DEPTH))\n",
    "train_df[\"depth\"] = [np.ones_like(train_df.loc[i][\"images\"]) * train_df.loc[i][\"z\"] / MAX_DEPTH\n",
    "                     for i in tqdm_notebook(train_df.index)]\n",
    "\n",
    "# Image in layer1 + depth in layer2\n",
    "train_df[\"images_d\"] = [np.dstack((train_df[\"images\"][i],train_df[\"depth\"][i])) for i in tqdm_notebook(train_df.index)]\n",
    "train_df[\"images_d\"][0].shape\n",
    "# Free up some RAM\n",
    "del depths_df\n",
    "# del train_df[\"images\"]\n",
    "# Sanity check\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the no use cross validation\n",
    "May be not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train, ids_valid = train_test_split(\n",
    "    train_df.index.values,\n",
    "    test_size=0.12, stratify=train_df.coverage_class, random_state=1337)\n",
    "my_test_pd = train_df.loc[train_df.index.isin(ids_valid)]\n",
    "train_df = train_df.loc[train_df.index.isin(ids_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(my_test_pd.shape)\n",
    "print(train_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut the train and valid set ，use K-flods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=8, random_state=1337, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "K_flods = 8\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = train_df.index.values\n",
    "y = train_df.coverage_class\n",
    "skf = StratifiedKFold(n_splits=K_flods,random_state=1337)\n",
    "skf.get_n_splits(X, y)\n",
    "print(skf)\n",
    "ids_train,ids_valid,x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test=[[] for x in range(10)]\n",
    "# X_whole = np.array(train_df.images_d.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 2)\n",
    "# y_whole = np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_whole = np.array(train_df.images.map(reflect_pad).tolist()).reshape(-1, 256, 256, 1)\n",
    "y_whole = np.array(train_df.masks.map(reflect_pad).tolist()).reshape(-1, 256, 256, 1)\n",
    "# xpad1=pad(resize(x_train[0,:,:,0], (101*2, 101*2), mode='constant', preserve_range=True),27,'reflect')\n",
    "# xpad2=pad(resize(x_train[1,:,:,0], (101*2, 101*2), mode='constant', preserve_range=True),27,'reflect')\n",
    "# print(xpad1.shape)\n",
    "# axs[2].imshow(xpad1,  cmap=\"Greys\")\n",
    "# axs[3].imshow(xpad2,  cmap=\"Greys\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(15,5))\n",
    "axs[0].imshow(X_whole[1,:,:,0],  cmap=\"Greys\")\n",
    "axs[1].imshow(y_whole[1,:,:,0],  cmap=\"Greys\")\n",
    "axs[2].imshow(np.array(train_df.images.map(upsample).tolist()).reshape(-1, 128, 128, 1)[1,:,:,0],  cmap=\"Greys\")\n",
    "axs[3].imshow(np.array(train_df.masks.map(upsample).tolist()).reshape(-1, 128, 128, 1)[1,:,:,0],  cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0th flod:\n",
      "TRAIN: (3496,) TEST: (504,)\n",
      "the 1th flod:\n",
      "TRAIN: (3497,) TEST: (503,)\n",
      "2\n",
      "(3496, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "for i,[train_index, test_index] in enumerate(skf.split(X, y)):\n",
    "    print(\"the %dth flod:\"%i)\n",
    "    print(\"TRAIN:\", train_index.shape, \"TEST:\", test_index.shape)\n",
    "    ids_train.append(X[train_index])\n",
    "    ids_valid.append(X[test_index])\n",
    "    #\n",
    "    x_train.append(X_whole[train_index])\n",
    "    x_valid.append(X_whole[test_index])\n",
    "    #\n",
    "    y_train.append(y_whole[train_index])\n",
    "    y_valid.append(y_whole[test_index]) \n",
    "    #\n",
    "    cov_train.append(train_df.coverage.values[train_index]) \n",
    "    cov_test.append(train_df.coverage.values[test_index])\n",
    "    #\n",
    "    depth_train.append(train_df.z.values[train_index]) \n",
    "    depth_test.append(train_df.z.values[test_index]) \n",
    "    \n",
    "    if i == 1:\n",
    "        break\n",
    "del X_whole,y_whole\n",
    "print(len(x_train))\n",
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee4da60a2585bfd1f87eb847b9737980c35a84ca",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 画各个flods的salt分布图，检验k-flods是否正确\n",
    "def plot_flods_coverage(cov,flods_num=5,mode='train'):\n",
    "    fig, axs = plt.subplots(1, flods_num+1, figsize=(15,5))\n",
    "    sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "    for i in range(1,flods_num+1):\n",
    "        sns.distplot(cov[i-1], bins=10, kde=False, ax=axs[i])\n",
    "        axs[i].set_xlabel(\"Coverage of k%d\"%(i-1))\n",
    "    plt.suptitle(\"Salt coverage of k-flods \"+mode)\n",
    "    axs[0].set_xlabel(\"Coverage\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_flods_coverage(cov_train,flods_num=7,mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_flods_coverage(cov_test,flods_num=5,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57f2ca1eb4bea73b1126638dfdb1d756ef3c917a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.distplot(train_df.z, label=\"Train\")\n",
    "# sns.distplot(test_df.z, label=\"Test\")\n",
    "# plt.legend()\n",
    "# plt.title(\"Depth distribution\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e527aa033723d7276e3ee35e7e90f14de9bbb043",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max_images = 60\n",
    "# grid_width = 15\n",
    "# grid_height = int(max_images / grid_width)\n",
    "# fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n",
    "# for i, idx in enumerate(train_df.index[:max_images]):\n",
    "#     img = train_df.loc[idx].images\n",
    "#     mask = train_df.loc[idx].masks\n",
    "#     ax = axs[int(i / grid_width), i % grid_width]\n",
    "#     ax.imshow(img, cmap=\"Greys\")\n",
    "#     ax.imshow(mask, alpha=0.3, cmap=\"Greens\")\n",
    "#     ax.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n",
    "#     ax.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n",
    "#     ax.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n",
    "#     ax.set_yticklabels([])\n",
    "#     ax.set_xticklabels([])\n",
    "# plt.suptitle(\"Green: salt. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5927c77a3d6d9b5215b00dd1540a4d5e2ab501e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "#     train_df.index.values,\n",
    "#     np.array(train_df.images_d.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 2), \n",
    "#     np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "#     train_df.coverage.values,\n",
    "#     train_df.z.values,\n",
    "#     test_size=0.2, stratify=train_df.coverage_class, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.util import pad\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15,5))\n",
    "axs[0].imshow(x_train[0,:,:,0],  cmap=\"Greys\")\n",
    "axs[1].imshow(x_train[1,:,:,0],  cmap=\"Greys\")\n",
    " \n",
    "xpad1=pad(resize(x_train[0,:,:,0], (101*2, 101*2), mode='constant', preserve_range=True),27,'reflect')\n",
    "xpad2=pad(resize(x_train[1,:,:,0], (101*2, 101*2), mode='constant', preserve_range=True),27,'reflect')\n",
    "print(xpad1.shape)\n",
    "axs[2].imshow(xpad1,  cmap=\"Greys\")\n",
    "axs[3].imshow(xpad2,  cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36da20e77216c0824ab6cb4d6963603c6db736ed",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmp_img = np.zeros((img_size_target, img_size_target), dtype=train_df.images.loc[ids_train[10]].dtype)\n",
    "# tmp_img[:img_size_ori, :img_size_ori] = train_df.images.loc[ids_train[10]]\n",
    "# fix, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "# axs[0].imshow(tmp_img, cmap=\"Greys\")\n",
    "# axs[0].set_title(\"Original image\")\n",
    "# axs[1].imshow(x_train[10].squeeze(), cmap=\"Greys\")\n",
    "# axs[1].set_title(\"Scaled image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "751db378b8b0ba53bf6bbd4da9ee405bc648bfe0"
   },
   "source": [
    "# Data argumantant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4c28f33e17759ef77ce17423db1821d735f0507b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    x_l_r_flip = [np.fliplr(x) for x in x_train[i]]\n",
    "    y_l_r_flip = [np.fliplr(x) for x in y_train[i]]\n",
    "    # x_u_d_flip = [np.flipud(x) for x in x_train]\n",
    "    # y_u_d_flip = [np.flipud(x) for x in y_train]\n",
    "    # x_t = [np.reshape(np.transpose(x),(img_size_target,img_size_target,2)) for x in x_train]\n",
    "    # y_t = [np.reshape(np.transpose(x),(img_size_target,img_size_target,1)) for x in y_train]\n",
    "    # x_train = np.append(x_train, x_u_d_flip, axis=0)\n",
    "    # y_train = np.append(y_train, y_u_d_flip, axis=0)\n",
    "    # x_train = np.append(x_train, x_t, axis=0)\n",
    "    # y_train = np.append(y_train, y_t, axis=0)\n",
    "    x_train[i] = np.append(x_train[i], x_l_r_flip, axis=0)\n",
    "    y_train[i] = np.append(y_train[i], y_l_r_flip, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "cac75b593bf29db252f09f4bd29e7ee938f6d00a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6992, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "359a03c11c3ccf547f59709c5b00351f58ac6dc2"
   },
   "source": [
    "## 对比度增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "513d0ac24c783eb673a0c953a594475439628f70",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from skimage import exposure\n",
    "# contrast = [np.dstack([np.array(exposure.rescale_intensity(\n",
    "#     img[:,:,0],in_range=(np.percentile(img[:,:,0], (1, 99))[0],np.percentile(img[:,:,0], (1, 99))[1]))),img[:,:,1]]) \n",
    "#             for img in tqdm_notebook(x_train)]\n",
    "# contrast = np.array(contrast)\n",
    "# x_train = np.append(x_train, contrast, axis=0)\n",
    "# y_train = np.append(y_train, y_train, axis=0)\n",
    "# x_train = np.append(x_train, x_l_r_flip, axis=0)\n",
    "# y_train = np.append(y_train, y_l_r_flip, axis=0)\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# del contrast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b5619ed63f9ca81965a0e05c94f6ea2ec59c3f8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x_train[110,:,:,0], cmap='binary')\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1,2,2)    \n",
    "plt.imshow(contrast[110,:,:,0], cmap='binary')\n",
    "plt.title('Contrast stretching')\n",
    "print(contrast.shape)\n",
    "print(contrast[110,60:64,60:64,1])\n",
    "print(x_train[110,60:64,60:64,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "793e717cbaa3e090c4e141eb4d9acac71551d745",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def random_shiff(x_train,y_train):\n",
    "    length = x_train.shape[0]\n",
    "    len_list = list(range(length))\n",
    "    shiff_index = np.random.shuffle(len_list)\n",
    "    return x_train[shiff_index:,:,:],y_train[shiff_index:,:,:]\n",
    "x_train,y_train = random_shiff(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d1550ba131ae8af33bedb2a0d1eee7bf420f6ed",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(np.array(x_t).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9450f13a7c48befebc835a60a67356c4cb715b2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fix, axs = plt.subplots(2, 2, figsize=(15,5))\n",
    "print(x_train.shape)\n",
    "axs[0][0].imshow(x_train[10,:,:,0], cmap=\"Greys\")\n",
    "axs[0][1].imshow(y_train[10,:,:,0], cmap=\"Greys\")\n",
    "axs[1][0].imshow((np.fliplr(x_train[10,:,:,0])), cmap=\"Greys\")\n",
    "axs[1][1].imshow((np.fliplr(y_train[10,:,:,0])), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73a311a8fa1ae5ebdc2d5fc7031878da65c17a7f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from PIL import Image, ImageEnhance, ImageOps, ImageFile\n",
    "# def randomRotation(image, mode=Image.BICUBIC):\n",
    "#     \"\"\"\n",
    "#      对图像进行随机任意角度(0~360度)旋转\n",
    "#     :param mode 邻近插值,双线性插值,双三次B样条插值(default)\n",
    "#     :param image PIL的图像image\n",
    "#     :return: 旋转转之后的图像\n",
    "#     \"\"\"\n",
    "#     random_angle = np.random.randint(1, 360)\n",
    "#     return image.rotate(random_angle, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b25e05e023add8abee16ba7303b91822fd2a017",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 10, figsize=(15,3))\n",
    "# for i in range(10):\n",
    "#     axs[0][i].imshow(x_train[i].squeeze(), cmap=\"Greys\")\n",
    "#     axs[0][i].imshow(y_train[i].squeeze(), cmap=\"Greens\", alpha=0.3)\n",
    "#     axs[1][i].imshow(x_train[int(len(x_train)/2 + i)].squeeze(), cmap=\"Greys\")\n",
    "#     axs[1][i].imshow(y_train[int(len(y_train)/2 + i)].squeeze(), cmap=\"Greens\", alpha=0.3)\n",
    "# fig.suptitle(\"Top row: original images, bottom row: augmented images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train[0][..., :1].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "def mean_iou(Y_true, Y_pred, score_thres=0.5):\n",
    "    \"\"\"Compute mean(IoU) metric\n",
    "    IoU = intersection / union\n",
    "    \n",
    "    For each (mask)threshold in provided range:\n",
    "     - convert probability mask to boolean mask based on given threshold\n",
    "     - score the mask 1 if(IoU > score_threshold(0.5))\n",
    "    Take the mean of the scoress\n",
    "\n",
    "    https://www.tensorflow.org/api_docs/python/tf/metrics/mean_iou\n",
    "    \"\"\"\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        Y_pred_bool = tf.to_int32(Y_pred > t) # boolean mask by threshold\n",
    "        score, update_op = tf.metrics.mean_iou(Y_true, Y_pred_bool, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            score = tf.identity(score) #!! use identity to transform score to tensor\n",
    "        prec.append(score) \n",
    "        \n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    gamma=0.5\n",
    "    alpha=0.25\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, K.sigmoid(y_pred)) + dice_loss(y_true, K.sigmoid(y_pred))\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = weight * (logit_y_pred * (1. - y_true) + \n",
    "                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0        \n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpt = 5\n",
    "DPT_SIZE = int(img_size_target/pow(2,dpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from segmentation_models.segmentation_models import Unet\n",
    "from segmentation_models.segmentation_models.utils import set_trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to Python 3.5's help utility!\n",
      "\n",
      "If this is your first time using Python, you should definitely check out\n",
      "the tutorial on the Internet at http://docs.python.org/3.5/tutorial/.\n",
      "\n",
      "Enter the name of any module, keyword, or topic to get help on writing\n",
      "Python programs and using Python modules.  To quit this help utility and\n",
      "return to the interpreter, just type \"quit\".\n",
      "\n",
      "To get a list of available modules, keywords, symbols, or topics, type\n",
      "\"modules\", \"keywords\", \"symbols\", or \"topics\".  Each module also comes\n",
      "with a one-line summary of what it does; to list the modules whose name\n",
      "or summary contain a given string such as \"spam\", type \"modules spam\".\n",
      "\n",
      "help> \n",
      "\n",
      "You are now leaving help and returning to the Python interpreter.\n",
      "If you want to ask for help on a particular object directly from the\n",
      "interpreter, you can type \"help(object)\".  Executing \"help('string')\"\n",
      "has the same effect as typing a particular string at the help> prompt.\n"
     ]
    }
   ],
   "source": [
    "help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "5c4e9830d4141afbc33423df276ec2051da8e224",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_69 (ZeroPadding2 (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d_69[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_70 (ZeroPadding2 (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_70[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_71 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_71[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_72 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_72[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_73 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_73[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_74 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_74[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_75 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_75[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_76 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_76[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 64, 64, 64)   0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_77 (ZeroPadding2 (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_77[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_78 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_78[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_79 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_79[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_80 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_80[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_81 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_81[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_82 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_82[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 32, 32, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_83 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_83[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_84 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_84[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 32, 32, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_85 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_85[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_86 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_86[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_87 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_87[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_88 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_88[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_89 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_89[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_90 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_90[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 16, 16, 256)  0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_91 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_91[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_92 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_92[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 16, 16, 256)  0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_93 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_93[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_94 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_94[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 16, 16, 256)  0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_95 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_95[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_96 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_96[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 16, 16, 256)  0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_97 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_97[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_98 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_98[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_99 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_99[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_100 (ZeroPadding (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_100[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_101 (ZeroPadding (None, 10, 10, 512)  0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_101[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_102 (ZeroPadding (None, 10, 10, 512)  0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_102[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 8, 8, 512)    0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsample (UpSamp (None, 16, 16, 512)  0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 768)  0           decoder_stage0_upsample[0][0]    \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_conv1 (Conv2D)   (None, 16, 16, 256)  1769472     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_bn1 (BatchNormal (None, 16, 16, 256)  1024        decoder_stage0_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_relu1 (Activatio (None, 16, 16, 256)  0           decoder_stage0_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_conv2 (Conv2D)   (None, 16, 16, 256)  589824      decoder_stage0_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_bn2 (BatchNormal (None, 16, 16, 256)  1024        decoder_stage0_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_relu2 (Activatio (None, 16, 16, 256)  0           decoder_stage0_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsample (UpSamp (None, 32, 32, 256)  0           decoder_stage0_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 384)  0           decoder_stage1_upsample[0][0]    \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_conv1 (Conv2D)   (None, 32, 32, 128)  442368      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_bn1 (BatchNormal (None, 32, 32, 128)  512         decoder_stage1_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_relu1 (Activatio (None, 32, 32, 128)  0           decoder_stage1_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_conv2 (Conv2D)   (None, 32, 32, 128)  147456      decoder_stage1_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_bn2 (BatchNormal (None, 32, 32, 128)  512         decoder_stage1_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_relu2 (Activatio (None, 32, 32, 128)  0           decoder_stage1_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsample (UpSamp (None, 64, 64, 128)  0           decoder_stage1_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 64, 64, 192)  0           decoder_stage2_upsample[0][0]    \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_conv1 (Conv2D)   (None, 64, 64, 64)   110592      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_bn1 (BatchNormal (None, 64, 64, 64)   256         decoder_stage2_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_relu1 (Activatio (None, 64, 64, 64)   0           decoder_stage2_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_conv2 (Conv2D)   (None, 64, 64, 64)   36864       decoder_stage2_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_bn2 (BatchNormal (None, 64, 64, 64)   256         decoder_stage2_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_relu2 (Activatio (None, 64, 64, 64)   0           decoder_stage2_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsample (UpSamp (None, 128, 128, 64) 0           decoder_stage2_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 128, 128, 128 0           decoder_stage3_upsample[0][0]    \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_conv1 (Conv2D)   (None, 128, 128, 32) 36864       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_bn1 (BatchNormal (None, 128, 128, 32) 128         decoder_stage3_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_relu1 (Activatio (None, 128, 128, 32) 0           decoder_stage3_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_conv2 (Conv2D)   (None, 128, 128, 32) 9216        decoder_stage3_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_bn2 (BatchNormal (None, 128, 128, 32) 128         decoder_stage3_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_relu2 (Activatio (None, 128, 128, 32) 0           decoder_stage3_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsample (UpSamp (None, 256, 256, 32) 0           decoder_stage3_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_conv1 (Conv2D)   (None, 256, 256, 16) 4608        decoder_stage4_upsample[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_bn1 (BatchNormal (None, 256, 256, 16) 64          decoder_stage4_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_relu1 (Activatio (None, 256, 256, 16) 0           decoder_stage4_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_conv2 (Conv2D)   (None, 256, 256, 16) 2304        decoder_stage4_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_bn2 (BatchNormal (None, 256, 256, 16) 64          decoder_stage4_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_relu2 (Activatio (None, 256, 256, 16) 0           decoder_stage4_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, 256, 256, 1)  145         decoder_stage4_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid (Activation)            (None, 256, 256, 1)  0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,456,154\n",
      "Trainable params: 24,438,804\n",
      "Non-trainable params: 17,350\n",
      "__________________________________________________________________________________________________\n",
      "Train on 6992 samples, validate on 504 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6992/6992 [==============================] - 113s 16ms/step - loss: 1.3087 - my_iou_metric: 0.4786 - val_loss: 1.2611 - val_my_iou_metric: 0.6401\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.64008, saving model to trained_models/0th_flod.model\n",
      "Epoch 2/100\n",
      "6992/6992 [==============================] - 105s 15ms/step - loss: 1.2344 - my_iou_metric: 0.6965 - val_loss: 1.2251 - val_my_iou_metric: 0.6984\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.64008 to 0.69841, saving model to trained_models/0th_flod.model\n",
      "Epoch 3/100\n",
      "6992/6992 [==============================] - 105s 15ms/step - loss: 1.2135 - my_iou_metric: 0.7422 - val_loss: 1.2035 - val_my_iou_metric: 0.7292\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.69841 to 0.72917, saving model to trained_models/0th_flod.model\n",
      "Epoch 4/100\n",
      "6992/6992 [==============================] - 105s 15ms/step - loss: 1.1998 - my_iou_metric: 0.7705 - val_loss: 1.2000 - val_my_iou_metric: 0.7496\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.72917 to 0.74960, saving model to trained_models/0th_flod.model\n",
      "Epoch 5/100\n",
      "6992/6992 [==============================] - 106s 15ms/step - loss: 1.1921 - my_iou_metric: 0.7887 - val_loss: 1.2008 - val_my_iou_metric: 0.7677\n",
      "\n",
      "Epoch 00005: val_my_iou_metric improved from 0.74960 to 0.76766, saving model to trained_models/0th_flod.model\n",
      "Epoch 6/100\n",
      "6992/6992 [==============================] - 105s 15ms/step - loss: 1.1901 - my_iou_metric: 0.7835 - val_loss: 1.2009 - val_my_iou_metric: 0.7585\n",
      "\n",
      "Epoch 00006: val_my_iou_metric did not improve from 0.76766\n",
      "Epoch 7/100\n",
      "6992/6992 [==============================] - 106s 15ms/step - loss: 1.1866 - my_iou_metric: 0.7955 - val_loss: 1.1937 - val_my_iou_metric: 0.7794\n",
      "\n",
      "Epoch 00007: val_my_iou_metric improved from 0.76766 to 0.77937, saving model to trained_models/0th_flod.model\n",
      "Epoch 8/100\n",
      "6992/6992 [==============================] - 105s 15ms/step - loss: 1.1808 - my_iou_metric: 0.8086 - val_loss: 1.2015 - val_my_iou_metric: 0.7442\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.77937\n",
      "Epoch 9/100\n",
      "6992/6992 [==============================] - 106s 15ms/step - loss: 1.1789 - my_iou_metric: 0.8213 - val_loss: 1.1909 - val_my_iou_metric: 0.7792\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.77937\n",
      "Epoch 10/100\n",
      "6992/6992 [==============================] - 106s 15ms/step - loss: 1.1764 - my_iou_metric: 0.8296 - val_loss: 1.1974 - val_my_iou_metric: 0.7665\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.77937\n",
      "Epoch 11/100\n",
      "6992/6992 [==============================] - 106s 15ms/step - loss: 1.1722 - my_iou_metric: 0.8455 - val_loss: 1.1878 - val_my_iou_metric: 0.7895\n",
      "\n",
      "Epoch 00011: val_my_iou_metric improved from 0.77937 to 0.78948, saving model to trained_models/0th_flod.model\n",
      "Epoch 12/100\n",
      "6992/6992 [==============================] - 106s 15ms/step - loss: 1.1731 - my_iou_metric: 0.8525 - val_loss: 1.1855 - val_my_iou_metric: 0.8030\n",
      "\n",
      "Epoch 00012: val_my_iou_metric improved from 0.78948 to 0.80298, saving model to trained_models/0th_flod.model\n",
      "Epoch 13/100\n",
      "6992/6992 [==============================] - 105s 15ms/step - loss: 1.1699 - my_iou_metric: 0.8574 - val_loss: 1.1872 - val_my_iou_metric: 0.7879\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.80298\n",
      "Epoch 14/100\n",
      "6992/6992 [==============================] - 105s 15ms/step - loss: 1.1707 - my_iou_metric: 0.8577 - val_loss: 1.1910 - val_my_iou_metric: 0.7794\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve from 0.80298\n",
      "Epoch 15/100\n",
      "6992/6992 [==============================] - 106s 15ms/step - loss: 1.1695 - my_iou_metric: 0.8607 - val_loss: 1.1837 - val_my_iou_metric: 0.8008\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.80298\n",
      "Epoch 16/100\n",
      "6992/6992 [==============================] - 105s 15ms/step - loss: 1.1700 - my_iou_metric: 0.8569 - val_loss: 1.1948 - val_my_iou_metric: 0.7544\n",
      "\n",
      "Epoch 00016: val_my_iou_metric did not improve from 0.80298\n",
      "Epoch 17/100\n",
      "6992/6992 [==============================] - 106s 15ms/step - loss: 1.1702 - my_iou_metric: 0.8592 - val_loss: 1.1989 - val_my_iou_metric: 0.7393\n",
      "\n",
      "Epoch 00017: val_my_iou_metric did not improve from 0.80298\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 18/100\n",
      "6992/6992 [==============================] - 104s 15ms/step - loss: 1.1685 - my_iou_metric: 0.8664 - val_loss: 1.1877 - val_my_iou_metric: 0.7950\n",
      "\n",
      "Epoch 00018: val_my_iou_metric did not improve from 0.80298\n",
      "Epoch 19/100\n",
      "6992/6992 [==============================] - 104s 15ms/step - loss: 1.1672 - my_iou_metric: 0.8844 - val_loss: 1.1874 - val_my_iou_metric: 0.7855\n",
      "\n",
      "Epoch 00019: val_my_iou_metric did not improve from 0.80298\n",
      "Epoch 20/100\n",
      "6992/6992 [==============================] - 104s 15ms/step - loss: 1.1657 - my_iou_metric: 0.8895 - val_loss: 1.1865 - val_my_iou_metric: 0.7867\n",
      "\n",
      "Epoch 00020: val_my_iou_metric did not improve from 0.80298\n",
      "Epoch 21/100\n",
      "6992/6992 [==============================] - 104s 15ms/step - loss: 1.1662 - my_iou_metric: 0.8915 - val_loss: 1.1867 - val_my_iou_metric: 0.7885\n",
      "\n",
      "Epoch 00021: val_my_iou_metric did not improve from 0.80298\n",
      "Epoch 22/100\n",
      "2400/6992 [=========>....................] - ETA: 1:06 - loss: 1.1552 - my_iou_metric: 0.8945"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5258388e4041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                           callbacks=[model_checkpoint, reduce_lr,early_stopping])\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mhistory_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 185\u001b[0;31m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_all = []\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "for i in range(0,1): \n",
    "    model = Unet(input_shape=(256,256,3),backbone_name='resnet34', encoder_weights='imagenet', \n",
    "                 freeze_encoder=False,decoder_use_batchnorm=True)\n",
    "    #model.load_weights('res50_keras.model')\n",
    "    adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    #sgd  = SGD(lr=0.0005, momentum=0.9, decay=0.0001, nesterov=False)\n",
    "    model.compile(loss=bce_dice_loss, optimizer=adam, metrics=[my_iou_metric])\n",
    "    #model.compile(loss=keras_lovasz_hinge, optimizer=sgd, metrics=[my_iou_metric])\n",
    "\n",
    "    model.summary()\n",
    "    # continue training    \"trained_models/%dth_flod.model\"%i\n",
    "    early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max', patience=10, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(\"trained_models/%dth_flod.model\"%i,monitor='val_my_iou_metric', \n",
    "                                   mode = 'max',  save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', \n",
    "                                   mode = 'max', factor=0.1, patience=5, min_lr=0.000001, verbose=1)\n",
    "\n",
    "    history = model.fit(np.repeat(x_train[i][..., :1],3,axis=-1),\n",
    "                          y_train[i],\n",
    "                          validation_data=(np.repeat(x_valid[i][..., :1],3,axis=-1),\n",
    "                          y_valid[i]), \n",
    "                          epochs=100,\n",
    "                          batch_size=32,\n",
    "                          callbacks=[model_checkpoint, reduce_lr,early_stopping])\n",
    "    history_all.append(history)\n",
    "    axs[i][0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    axs[i][0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    axs[i][1].plot(history.epoch, history.history[\"acc\"], label=\"Train accuracy\")\n",
    "    axs[i][1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation accuracy\")\n",
    "    axs[i][2].plot(history.epoch, history.history[\"mean_iou\"], label=\"Train iou\")\n",
    "    axs[i][2].plot(history.epoch, history.history[\"val_mean_iou\"], label=\"Validation iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predit with K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predit_with_kfolds(K_flods,x_img):\n",
    "    preds_valid_all = []\n",
    "    for i in range(K_flods):\n",
    "        model_flods = load_model(\"trained_models/%dth_flod.model\"%i, custom_objects={'mean_iou': mean_iou})\n",
    "    #     model.append(model_flods)\n",
    "        #此处的validation为第0组flod\n",
    "        preds_valid_flods = model_flods.predict(np.repeat(x_img,3,axis=-1))\n",
    "        print(preds_valid_flods.shape)\n",
    "        preds_valid_flods = np.array([downsample(x) for x in preds_valid_flods[:,27:229,27:229,:]])\n",
    "        print(preds_valid_flods.shape)\n",
    "        preds_valid_all.append(preds_valid_flods)\n",
    "    preds_valid = (preds_valid_all[0]+preds_valid_all[1]+preds_valid_all[2]+preds_valid_all[3]+preds_valid_all[4])/5\n",
    "    return preds_valid\n",
    "\n",
    "def predit_with_one_fold(model_num,x_img):\n",
    "    model_flods = load_model(\"trained_models/%dth_flod.model\"%model_num, custom_objects=\n",
    "                             {'my_iou_metric': my_iou_metric,'bce_dice_loss':bce_dice_loss})\n",
    "    #     model.append(model_flods)\n",
    "        #此处的validation为第0组flod\n",
    "    preds_valid_flods = model_flods.predict(np.repeat(x_img,3,axis=-1))\n",
    "    print(preds_valid_flods.shape)\n",
    "    preds_valid_flods = np.array([downsample(x) for x in preds_valid_flods[:,27:229,27:229,:]])\n",
    "    print(preds_valid_flods.shape)\n",
    "    return preds_valid_flods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e95793351bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalid_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreflect_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreflect_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'images'"
     ]
    }
   ],
   "source": [
    "valid_x = np.array(x_valid.images.map(reflect_pad).tolist()).reshape(-1, 256, 256, 1)\n",
    "valid_y = np.array(y_valid.masks.map(reflect_pad).tolist()).reshape(-1, 256, 256, 1)\n",
    "valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 256, 256, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_valid[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one model predit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 256, 256, 1)\n",
      "(504, 101, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "preds_valid = predit_with_one_fold(0,x_valid[0])\n",
    "y_valid = np.array([downsample(x) for x in y_valid[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 101, 101, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function:bce_dice_loss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e45a5fe70562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_flods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trained_models/0th_flod.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpreds_valid_flods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_flods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_valid_flods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds_valid_flods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m229\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m229\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_valid_flods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    287\u001b[0m                           \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                           \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                           sample_weight_mode=sample_weight_mode)\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Set optimizer weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_function\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    112\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                                     printable_module_name='loss function')\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 165\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function:bce_dice_loss"
     ]
    }
   ],
   "source": [
    "model_flods = load_model(\"trained_models/0th_flod.model\")\n",
    "preds_valid_flods = model_flods.predict(np.repeat(x_valid[0][..., :1],3,axis=-1))\n",
    "print(preds_valid_flods.shape)\n",
    "preds_valid = np.array([downsample(x) for x in preds_valid_flods[:,27:229,27:229,:]])\n",
    "print(preds_valid_flods.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_valid = np.array([downsample(x) for x in  y_valid[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53ff83d85555e9e1d94c07c49396a5e0230a9cd0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_valid = predit_with_kfolds(K_flods,valid_x)\n",
    "# preds_valid_all = []\n",
    "# for i in range(K_flods):\n",
    "#     model_flods = load_model(\"trained_models/%dth_flod.model\"%i, custom_objects={'mean_iou': mean_iou})\n",
    "# #     model.append(model_flods)\n",
    "#     #此处的validation为第0组flod\n",
    "#     preds_valid_flods = model_flods.predict({'img': x_valid[0][..., :1], \n",
    "#                             'depth': x_valid[0][:, 60:60+DPT_SIZE, 60:60+DPT_SIZE, 1:]}).reshape(-1, img_size_target, img_size_target)\n",
    "#     preds_valid_flods = np.array([downsample(x) for x in preds_valid_flods])\n",
    "#     preds_valid_all.append(preds_valid_flods)\n",
    "# preds_valid = (preds_valid_all[0]+preds_valid_all[1]+preds_valid_all[2]+preds_valid_all[3]+preds_valid_all[4])/5\n",
    "y_valid = np.array([downsample(x) for x in valid_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e13865d3cb826f3c0d45c9146342e0253d0a8e77",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max_images = 60\n",
    "# grid_width = 15\n",
    "# grid_height = int(max_images / grid_width)\n",
    "# fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n",
    "# for i, idx in enumerate(ids_valid[60:60+max_images]):\n",
    "#     img = train_df.loc[idx].images\n",
    "#     mask = train_df.loc[idx].masks\n",
    "#     pred = preds_valid[i]\n",
    "#     ax = axs[int(i / grid_width), i % grid_width]\n",
    "#     ax.imshow(img, cmap=\"Greys\")\n",
    "#     ax.imshow(mask, alpha=0.3, cmap=\"Greens\")\n",
    "#     ax.imshow(pred, alpha=0.3, cmap=\"OrRd\")\n",
    "#     ax.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n",
    "#     ax.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n",
    "#     ax.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n",
    "#     ax.set_yticklabels([])\n",
    "#     ax.set_xticklabels([])\n",
    "# plt.suptitle(\"Green: salt, Red: prediction. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "5045277ad87d64a3ed3f43eff7862ef19131177c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "a85541b44a6b65a8616e26e0950f2ba1b7011bd0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155946f94a22403baefb920a7c8143a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0, 1, 50)\n",
    "ious = np.array([iou_metric_batch(y_valid, np.int32(preds_valid > threshold)) for threshold in tqdm_notebook(thresholds)])\n",
    "threshold_best_index = np.argmax(ious[9:-10]) + 9\n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "ad0d1079cf033cd6bd472cbe7d1ad8d6bb852293"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb7e2a31dd8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAETCAYAAACMfflIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYuKFCGEkJBFRYoQQkjI+gdui92NdPAspgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7e2a1a908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cd41507b1c26a16f47abf48cad2b6ab81be5508c"
   },
   "source": [
    "\n",
    "# Another sanity check with adjusted threshold\n",
    "\n",
    "Again some sample images with the adjusted threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "212e2c49e7ce3b065c456ee5a9f6ad103744f511",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max_images = 60\n",
    "# grid_width = 15\n",
    "# grid_height = int(max_images / grid_width)\n",
    "# fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n",
    "# for i, idx in enumerate(ids_valid[:max_images]):\n",
    "#     img = train_df.loc[idx].images\n",
    "#     mask = train_df.loc[idx].masks\n",
    "#     pred = preds_valid[i]\n",
    "#     ax = axs[int(i / grid_width), i % grid_width]\n",
    "#     ax.imshow(img, cmap=\"Greys\")\n",
    "#     ax.imshow(mask, alpha=0.3, cmap=\"Greens\")\n",
    "#     ax.imshow(np.array(np.round(pred > threshold_best), dtype=np.float32), alpha=0.3, cmap=\"OrRd\")\n",
    "#     ax.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n",
    "#     ax.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n",
    "#     ax.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n",
    "#     ax.set_yticklabels([])\n",
    "#     ax.set_xticklabels([])\n",
    "# plt.suptitle(\"Green: salt, Red: prediction. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe077821181c226c4cfc2ea1c0844314cb61a182"
   },
   "source": [
    "\n",
    "# Submission\n",
    "\n",
    "Load, predict and submit the test image predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e650eb0e1773f9de1e3c555b1dc1961dbb30a8f0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source https://www.kaggle.com/bguberfain/unet-with-depth\n",
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6be1a40a948e5bad6e165d2228a613ed16534224",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.array([reflect_pad(np.array(load_img(\"test/images/{}.png\".format(idx), grayscale=True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "# Create depth layer\n",
    "del x_train,y_train,x_valid,y_valid\n",
    "# x_test_d = [np.ones((DPT_SIZE,DPT_SIZE,1)) * (test_df.loc[i][\"z\"] / MAX_DEPTH)\n",
    "#                      for i in tqdm_notebook(test_df.index)] \n",
    "# x_test_d = np.array(x_test_d).reshape(-1, DPT_SIZE, DPT_SIZE, 1)\n",
    "# x_test_d.shape\n",
    "preds_test = predit_with_one_fold(0,x_test)[:,27:229,27:229,:]\n",
    "\n",
    "# preds_test = predit_with_kfolds(K_flods,x_test)[:,27:229,27:229,:]\n",
    "# preds_test = model.predict({'img': x_test, 'depth': x_test_d})\n",
    "pred_dict = {idx: RLenc(np.round(downsample(preds_test[i]) > \n",
    "            threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
